{
    "title": "ClimateX: Do LLMs Accurately Assess Human Expert Confidence in Climate\n  Statements?",
    "authors": [
        "Romain Lacombe",
        "Kerrie Wu",
        "Eddie Dilworth"
    ],
    "abstract": "  Evaluating the accuracy of outputs generated by Large Language Models (LLMs)\nis especially important in the climate science and policy domain. We introduce\nthe Expert Confidence in Climate Statements (ClimateX) dataset, a novel,\ncurated, expert-labeled dataset consisting of 8094 climate statements collected\nfrom the latest Intergovernmental Panel on Climate Change (IPCC) reports,\nlabeled with their associated confidence levels. Using this dataset, we show\nthat recent LLMs can classify human expert confidence in climate-related\nstatements, especially in a few-shot learning setting, but with limited (up to\n47%) accuracy. Overall, models exhibit consistent and significant\nover-confidence on low and medium confidence statements. We highlight\nimplications of our results for climate communication, LLMs evaluation\nstrategies, and the use of LLMs in information retrieval systems.\n",
    "published_date": "2023-11-28T10:26:57Z",
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2311.17107v1"
}