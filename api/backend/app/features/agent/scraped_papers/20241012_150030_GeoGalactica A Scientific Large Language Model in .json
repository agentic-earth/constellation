{
    "title": "GeoGalactica: A Scientific Large Language Model in Geoscience",
    "authors": [
        "Zhouhan Lin",
        "Cheng Deng",
        "Le Zhou",
        "Tianhang Zhang",
        "Yi Xu",
        "Yutong Xu",
        "Zhongmou He",
        "Yuanyuan Shi",
        "Beiya Dai",
        "Yunchong Song",
        "Boyi Zeng",
        "Qiyuan Chen",
        "Yuxun Miao",
        "Bo Xue",
        "Shu Wang",
        "Luoyi Fu",
        "Weinan Zhang",
        "Junxian He",
        "Yunqiang Zhu",
        "Xinbing Wang",
        "Chenghu Zhou"
    ],
    "abstract": "  Large language models (LLMs) have achieved huge success for their general\nknowledge and ability to solve a wide spectrum of tasks in natural language\nprocessing (NLP). Due to their impressive abilities, LLMs have shed light on\npotential inter-discipline applications to foster scientific discoveries of a\nspecific domain by using artificial intelligence (AI for science, AI4S). In the\nmeantime, utilizing NLP techniques in geoscience research and practice is wide\nand convoluted, contributing from knowledge extraction and document\nclassification to question answering and knowledge discovery. In this work, we\ntake the initial step to leverage LLM for science, through a rather\nstraightforward approach. We try to specialize an LLM into geoscience, by\nfurther pre-training the model with a vast amount of texts in geoscience, as\nwell as supervised fine-tuning (SFT) the resulting model with our custom\ncollected instruction tuning dataset. These efforts result in a model\nGeoGalactica consisting of 30 billion parameters. To our best knowledge, it is\nthe largest language model for the geoscience domain. More specifically,\nGeoGalactica is from further pre-training of Galactica. We train GeoGalactica\nover a geoscience-related text corpus containing 65 billion tokens, preserving\nas the largest geoscience-specific text corpus. Then we fine-tune the model\nwith 1 million pairs of instruction-tuning data consisting of questions that\ndemand professional geoscience knowledge to answer. In this technical report,\nwe will illustrate in detail all aspects of GeoGalactica, including data\ncollection, data cleaning, base model selection, pre-training, SFT, and\nevaluation. We open-source our data curation tools and the checkpoints of\nGeoGalactica during the first 3/4 of pre-training.\n",
    "published_date": "2023-12-31T09:22:54Z",
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2401.00434v2"
}