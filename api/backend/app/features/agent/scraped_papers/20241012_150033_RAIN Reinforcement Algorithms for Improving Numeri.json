{
    "title": "RAIN: Reinforcement Algorithms for Improving Numerical Weather and\n  Climate Models",
    "authors": [
        "Pritthijit Nath",
        "Henry Moss",
        "Emily Shuckburgh",
        "Mark Webb"
    ],
    "abstract": "  This study explores integrating reinforcement learning (RL) with idealised\nclimate models to address key parameterisation challenges in climate science.\nCurrent climate models rely on complex mathematical parameterisations to\nrepresent sub-grid scale processes, which can introduce substantial\nuncertainties. RL offers capabilities to enhance these parameterisation\nschemes, including direct interaction, handling sparse or delayed feedback,\ncontinuous online learning, and long-term optimisation. We evaluate the\nperformance of eight RL algorithms on two idealised environments: one for\ntemperature bias correction, another for radiative-convective equilibrium (RCE)\nimitating real-world computational constraints. Results show different RL\napproaches excel in different climate scenarios with exploration algorithms\nperforming better in bias correction, while exploitation algorithms proving\nmore effective for RCE. These findings support the potential of RL-based\nparameterisation schemes to be integrated into global climate models, improving\naccuracy and efficiency in capturing complex climate dynamics. Overall, this\nwork represents an important first step towards leveraging RL to enhance\nclimate model accuracy, critical for improving climate understanding and\npredictions. Code accessible at https://github.com/p3jitnath/climate-rl.\n",
    "published_date": "2024-08-28T20:10:46Z",
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2408.16118v1"
}